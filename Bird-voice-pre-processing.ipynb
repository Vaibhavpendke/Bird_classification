{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f99e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import colorednoise as cn\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ffceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dir = 'dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9141672",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(audio_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50235191",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms_dir = 'spectrogram/'\n",
    "if not os.path.exists(spectrograms_dir):\n",
    "    os.makedirs(spectrograms_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "335e9147",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scale = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2b864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time and frequency masking parameters\n",
    "time_mask_param = 10\n",
    "freq_mask_param = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc7509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time and frequency masking transformations\n",
    "time_masking = T.TimeMasking(time_mask_param=time_mask_param)\n",
    "freq_masking = T.FrequencyMasking(freq_mask_param=freq_mask_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9b2a4f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1009\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1059\n",
      "  return f(*args, **kwargs)\n",
      " 10%|████████▏                                                                         | 1/10 [02:40<24:01, 160.21s/it]C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1836\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1412\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=324\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1941\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=177\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1257\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1831\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1944\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1764\n",
      "  return f(*args, **kwargs)\n",
      " 30%|████████████████████████▌                                                         | 3/10 [12:10<25:56, 222.39s/it]C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=1368\n",
      "  return f(*args, **kwargs)\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 9/10 [28:29<02:07, 127.99s/it]C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=353\n",
      "  return f(*args, **kwargs)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [29:45<00:00, 178.52s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loop through all the directories (bird species)\n",
    "for directory in tqdm(os.listdir(audio_dir)):\n",
    "    \n",
    "    # Create a new directory for each bird species inside the \"spectrograms\" directory\n",
    "    output_dir = os.path.join(spectrograms_dir, directory)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Get a list of all the audio files in the current directory\n",
    "    file_list = os.listdir(os.path.join(audio_dir, directory))\n",
    "    \n",
    "    # Loop through all the audio files in the current directory\n",
    "    for filename in file_list:\n",
    "        \n",
    "        # Load the audio file\n",
    "        file_path = os.path.join(audio_dir, directory, filename)\n",
    "        y, sr = librosa.load(file_path, duration=45)\n",
    "        \n",
    "        # Add pink noise augmentation to the audio file\n",
    "        pink_noise = np.random.normal(scale=noise_scale, size=y.shape)\n",
    "        y_augmented = y + pink_noise\n",
    "        \n",
    "        # Compute the mel spectrogram of the augmented audio file\n",
    "        S = librosa.feature.melspectrogram(y=y_augmented, sr=sr, n_mels=128, fmax=8000)\n",
    "        S_dB = librosa.amplitude_to_db(S, ref=np.max)\n",
    "        \n",
    "        # Split the spectrogram into three equal parts\n",
    "        n_frames = S_dB.shape[1]\n",
    "        frame_splits = np.array_split(np.arange(n_frames), 3)\n",
    "        \n",
    "        # Split the audio file into chunks and process each chunk separately\n",
    "        chunk_size = 10 * sr  # 10 seconds\n",
    "        for i, chunk_start in enumerate(range(0, len(y_augmented), chunk_size)):\n",
    "            # Get the start and end samples of the current chunk\n",
    "            chunk_end = chunk_start + chunk_size\n",
    "            chunk = y_augmented[chunk_start:chunk_end]\n",
    "            \n",
    "            # Compute the mel spectrogram of the current chunk\n",
    "            S = librosa.feature.melspectrogram(y=chunk, sr=sr, n_mels=128, fmax=8000)\n",
    "            S_dB = librosa.amplitude_to_db(S, ref=np.max)\n",
    "            \n",
    "            # Apply time and frequency masking to the current chunk\n",
    "            augmented_melspec = torch.Tensor(S_dB).unsqueeze(0)  # unsqueeze to add batch dimension\n",
    "            augmented_melspec = time_masking(augmented_melspec)\n",
    "            augmented_melspec = freq_masking(augmented_melspec)\n",
    "            S_dB = augmented_melspec.squeeze(0).numpy()  # squeeze to remove batch dimension and convert back to NumPy array\n",
    "            \n",
    "            # Save the spectrogram as a PNG image file in the current directory of the \"spectrograms\" directory\n",
    "            output_file = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_{i+1}.png\")\n",
    "            plt.figure(figsize=(10.00, 6.00), dpi=100)\n",
    "            librosa.display.specshow(S_dB, x_axis='time', y_axis='mel', sr=sr, fmax=8000)\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_file, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417edd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
